FROM ollama/ollama

# Entrypoint: primero descarga el modelo, luego arranca el servidor
CMD sh -c "ollama pull llama3:8b-instruct-q2_K && ollama serve"
